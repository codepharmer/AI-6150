{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e42cf153",
   "metadata": {},
   "source": [
    "**Aishwarya Singh, Nosson Weissman**\n",
    "\n",
    "**DAV 6150 - Data Science**\n",
    "\n",
    "**Professor James Topor**\n",
    "\n",
    "**Summer 2022**\n",
    "\n",
    "__DAV 6150 Practical (Module 5) : Performance Metrics__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dcb3a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37ff68c",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "In this assignment we are given a dataset containing categorical data predictions. <br>\n",
    "Considering only the data pertaining to the predicition-correctness, we define our own functions and compare with their respective sklearn comparable functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "82bd10fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>skinfold</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "      <th>scored.class</th>\n",
       "      <th>scored.probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>124</td>\n",
       "      <td>70</td>\n",
       "      <td>33</td>\n",
       "      <td>215</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0.161</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.328452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>76</td>\n",
       "      <td>27</td>\n",
       "      <td>200</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0.483</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>62</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.678</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.109660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>64</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>29.2</td>\n",
       "      <td>0.192</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>29.3</td>\n",
       "      <td>0.317</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>74</td>\n",
       "      <td>40</td>\n",
       "      <td>77</td>\n",
       "      <td>34.1</td>\n",
       "      <td>0.269</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.311420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>4</td>\n",
       "      <td>146</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.520</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.707210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>8</td>\n",
       "      <td>188</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.9</td>\n",
       "      <td>0.137</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.888277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>9</td>\n",
       "      <td>120</td>\n",
       "      <td>72</td>\n",
       "      <td>22</td>\n",
       "      <td>56</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.733</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.422468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>86</td>\n",
       "      <td>17</td>\n",
       "      <td>105</td>\n",
       "      <td>29.3</td>\n",
       "      <td>0.695</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.119981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnant  glucose  diastolic  skinfold  insulin   bmi  pedigree  age  \\\n",
       "0           7      124         70        33      215  25.5     0.161   37   \n",
       "1           2      122         76        27      200  35.9     0.483   26   \n",
       "2           3      107         62        13       48  22.9     0.678   23   \n",
       "3           1       91         64        24        0  29.2     0.192   21   \n",
       "4           4       83         86        19        0  29.3     0.317   34   \n",
       "..        ...      ...        ...       ...      ...   ...       ...  ...   \n",
       "176         5      123         74        40       77  34.1     0.269   28   \n",
       "177         4      146         78         0        0  38.5     0.520   67   \n",
       "178         8      188         78         0        0  47.9     0.137   43   \n",
       "179         9      120         72        22       56  20.8     0.733   48   \n",
       "180         0      102         86        17      105  29.3     0.695   27   \n",
       "\n",
       "     class  scored.class  scored.probability  \n",
       "0        0             0            0.328452  \n",
       "1        0             0            0.273190  \n",
       "2        1             0            0.109660  \n",
       "3        0             0            0.055998  \n",
       "4        0             0            0.100491  \n",
       "..     ...           ...                 ...  \n",
       "176      0             0            0.311420  \n",
       "177      1             1            0.707210  \n",
       "178      1             1            0.888277  \n",
       "179      0             0            0.422468  \n",
       "180      0             0            0.119981  \n",
       "\n",
       "[181 rows x 11 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1-2. load the data from github\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/codepharmer/AI-6150/main/M5%20Performance%20Metrics/M5_Data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe1f1e0",
   "metadata": {},
   "source": [
    "#### Quick check that no data is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abeb4980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pregnant              0\n",
       "glucose               0\n",
       "diastolic             0\n",
       "skinfold              0\n",
       "insulin               0\n",
       "bmi                   0\n",
       "pedigree              0\n",
       "age                   0\n",
       "class                 0\n",
       "scored.class          0\n",
       "scored.probability    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fb2171",
   "metadata": {},
   "source": [
    "#### As per assignment instructions, we focus on the last three columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6445c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = df[[df.columns[col] for col in [8,9,10]]]\n",
    "obs = raw_data['class']\n",
    "pred = raw_data['scored.class']\n",
    "pred_p = raw_data['scored.class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df0972d",
   "metadata": {},
   "source": [
    "### We can use the pandas crosstab function to create a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35b13f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>class</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scored.class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "class           0   1\n",
       "scored.class         \n",
       "0             119  30\n",
       "1               5  27"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.\n",
    "pd.crosstab(raw_data['scored.class'],raw_data['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68488233",
   "metadata": {},
   "source": [
    "### Using the pandas flatten function, we can extract the confusion matrix values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c0ee9dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119, 30, 5, 27)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4.\n",
    "pd_cf = pd.crosstab(raw_data['scored.class'],raw_data['class'])\n",
    "tn,fn,fp,tp =pd_cf.values.flatten()\n",
    "tn,fn,fp,tp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66962c47",
   "metadata": {},
   "source": [
    "### Definitions of metrics:\n",
    "\n",
    "$tp$ = true positive, $fp$ = false positive, $tn$ = true negative, $fn$ = false negative\n",
    "\n",
    "**Precision** =$\\Large\\frac{tp}{tp+fp}$\n",
    "\n",
    "**Accuracy** = $\\Large\\frac{tp+tn}{tp+fp+tn+fn}$\n",
    "\n",
    "**Sensitivity** = $\\Large\\frac{tp}{tp+fn}$\n",
    "\n",
    "**Specificity** = $\\Large\\frac{tn}{tn+fp}$\n",
    "\n",
    "**F1** = $\\Large\\frac{tp}{tp+0.5(fp+fn)}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dea6516",
   "metadata": {},
   "source": [
    "### Below we define a function which we will use as a helper within our metric functions defined below \n",
    "The function, given binary classification data, creates a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de2526b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix(pred, obs):\n",
    "    # get indices for pred value == True\n",
    "    pred_true = [i for i in range(len(pred)) if pred[i] == True]\n",
    "    # get indices for when pred value == False\n",
    "    pred_false = [i for i in range(len(pred)) if pred[i] == False]\n",
    "    # get the count of true negatives, true positives etc.\n",
    "    tn = len([i for i in pred_false if obs[i] == False])\n",
    "    tp = len([i for i in pred_true if obs[i] == True])\n",
    "    fp = len([i for i in pred_true if obs[i] == False])\n",
    "    fn = len([i for i in pred_false if obs[i] == True])\n",
    "    # return confusion matrix of pred obs\n",
    "    return (pd.DataFrame({'obs_0':[tn,fp],'obs_1':[fn,tp]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5d24a7",
   "metadata": {},
   "source": [
    "### In the following five cells we define functions to calculate correcness metrics for binary classification data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0090050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred,obs):\n",
    "    #accuracy = (tp+tn)/(tp+fp+tn+fn)\n",
    "    # generate confusion matrix for data\n",
    "    cf = create_confusion_matrix(pred, obs)\n",
    "    tn,fn,fp,tp = cf.values.flatten()\n",
    "    return (tp+tn)/(tp+fp+tn+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2f7bee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(pred,obs):\n",
    "    #precision = tp / (tp+fp)\n",
    "    # generate confusion matrix for data\n",
    "    cf = create_confusion_matrix(pred, obs)\n",
    "    # extract values from confusion matrix\n",
    "    tn,fn,fp,tp = cf.values.flatten()\n",
    "    return (tp/(tp+fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "65fe2a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity(pred,obs):\n",
    "    #sensitivity = tp / (tp+fn)\n",
    "    # generate confusion matrix for data\n",
    "    cf = create_confusion_matrix(pred, obs)\n",
    "    tn,fn,fp,tp = cf.values.flatten()\n",
    "    return  tp / (tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5b9d73f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity(pred,obs):\n",
    "    #specificity = tn / (tn+fp)\n",
    "    # generate confusion matrix for data\n",
    "    cf = create_confusion_matrix(pred, obs)\n",
    "    tn,fn,fp,tp = cf.values.flatten()\n",
    "    return tn / (tn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "57acc46c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def f1(pred,obs):\n",
    "    #f1 = tp/(tp+.5(fp+fn))\n",
    "    # generate confusion matrix for data\n",
    "    cf = create_confusion_matrix(pred, obs)\n",
    "    tn,fn,fp,tp = cf.values.flatten()\n",
    "    return  tp/(tp+.5*(fp+fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526a7e58",
   "metadata": {},
   "source": [
    "### Now, using the functions defined above, and the data pulled from Github we compute each metric and print the results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0b75b140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8066298342541437\n",
      "precision:  0.84375\n",
      "sensitivity:  0.47368421052631576\n",
      "specificity:  0.9596774193548387\n",
      "f1 score:  0.6067415730337079\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: ',accuracy(pred, obs))\n",
    "print('precision: ',precision(pred, obs))\n",
    "print('sensitivity: ',sensitivity(pred,obs))\n",
    "print('specificity: ',specificity(pred,obs))\n",
    "print('f1 score: ',f1(pred,obs))\n",
    "# metrics.classification_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3699e42",
   "metadata": {},
   "source": [
    "### We compare our functions with the sklearn built-in functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ae7d50b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[119,  30],\n",
       "       [  5,  27]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy matches sklearn:  True\n",
      "precision matches sklearn:  True\n",
      "sensitivity matches sklearn:  True\n",
      "f1 score matches sklearn:  True\n"
     ]
    }
   ],
   "source": [
    "#12.\n",
    "display(metrics.confusion_matrix(pred,obs))\n",
    "print('accuracy matches sklearn: ', metrics.accuracy_score(obs,pred) == accuracy(pred, obs))\n",
    "print('precision matches sklearn: ',metrics.precision_score(obs,pred) == precision(pred,obs))\n",
    "print('sensitivity matches sklearn: ',metrics.recall_score(obs,pred) == sensitivity(pred,obs))\n",
    "print('f1 score matches sklearn: ',metrics.f1_score(obs,pred) == f1(pred,obs))\n",
    "# metrics.classification_report(pred,obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ba01b325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84375"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score()\n",
    "# precision(pred,obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "781faaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[119,   5],\n",
       "       [ 30,  27]], dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(obs,pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
